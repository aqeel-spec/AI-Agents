{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33d3ddf3",
   "metadata": {},
   "source": [
    "# Agents\n",
    "\n",
    "Agents are the core building block in your apps. An agent is a large language model (LLM), configured with instructions and tools."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd407a41",
   "metadata": {},
   "source": [
    "## Basic configuration\n",
    "\n",
    "Most common properties of an agent we will configure are:\n",
    "  - `name` : Required string to identify the agent.\n",
    "  - `instructions` : `Developer message` || `system prompt`\n",
    "  - `model` : which LLM to use, and optional model_settings to configure model tuning parameters like temperature, top_p, etc.\n",
    "  - `tools` : List of tools to use in the agent.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1749d8ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in d:\\2025_practice\\ai-agents\\openai agents sdk (official docs)\\agentic_env\\lib\\site-packages (25.1.1)\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd19706",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "!pip install openai-agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6153891",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import Agent, ModelSettings, function_tool\n",
    "\n",
    "@function_tool\n",
    "def get_weather(city : str) -> str:\n",
    "    \"\"\"\n",
    "    Get the current weather for a given city.\n",
    "    \"\"\"\n",
    "    return f\"Current weather in {city} is sunny.\"\n",
    "\n",
    "agent = Agent(\n",
    "    name=\"WeatherBot\",\n",
    "    instructions=\"You are a helpful assistant that provides weather information.\",\n",
    "    model=\"o3-mini\",\n",
    "    tools=[get_weather],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9305ce",
   "metadata": {},
   "source": [
    "## Context\n",
    "\n",
    "### 1. **Generic Context Type**\n",
    "`Agents are generic on their context type` means that the `agent` is designed to work with any kind of `context`, without being tied to a specific type. This allows the agent to be flexible and adaptable to different use cases.\n",
    "\n",
    "### 2. **Context Type**\n",
    "`ContextType` is a type that represents the type of context that the agent is working with. It can be any type that the agent needs to interact with, such as a `list`, `dictionary`, `string`, or any other data structure.\n",
    "\n",
    "- **Context as Dependency Injection**:  \n",
    "  The context can be seen as a dependency that the agent needs to function. This dependency can be injected into the agent through its constructor or other methods, allowing the agent to be decoupled from any specific implementation details.\n",
    "\n",
    "### 3. **How it Works**\n",
    "- When the `Runner.run()` method is executed, a `Context` object is created and passed into the agent.\n",
    "- This context is passed along to every agent, tool, handoff, or component used during the agent's run.\n",
    "- The context is used to store and share dependencies and state between different components.\n",
    "\n",
    "### 4. **Example Usage**\n",
    "\n",
    "```python\n",
    "class MyContext:\n",
    "    def __init__(self, config, database):\n",
    "        self.config = config\n",
    "        self.database = database\n",
    "\n",
    "class MyAgent:\n",
    "    def __init__(self, context):\n",
    "        self.context = context\n",
    "\n",
    "    def run(self):\n",
    "        print(f\"Connecting to database: {self.context.database}\")\n",
    "        print(f\"Using config: {self.context.config}\")\n",
    "\n",
    "# Create a context object with the required dependencies\n",
    "context = MyContext(config={\"api_key\": \"your-api-key\"}, database=\"my_database\")\n",
    "\n",
    "# Pass the context to the agent\n",
    "agent = MyAgent(context)\n",
    "\n",
    "# Run the agent\n",
    "agent.run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf51b96",
   "metadata": {},
   "source": [
    "Here is official docs example\n",
    "\n",
    "```python\n",
    "@dataclass\n",
    "class UserContext:\n",
    "    uid: str\n",
    "    is_pro_user: bool\n",
    "\n",
    "    async def fetch_purchases() -> list[Purchase]:\n",
    "        return ...\n",
    "\n",
    "agent = Agent[UserContext](\n",
    "    ...,\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fdc01bf",
   "metadata": {},
   "source": [
    "## **Output types**\n",
    "\n",
    "By default, agents produce plain text (i.e. str) outputs. \n",
    "If you want the agent to produce a particular type of output, you can use the `output_type` parameter.\n",
    "A common choice is to use `Pydantic` `objects`, but we support any type that can be wrapped in a Pydantic `TypeAdapter` - dataclasses, lists, TypedDict, etc.\n",
    "\n",
    "```python\n",
    "    from pydantic import BaseModel\n",
    "    from agents import Agent\n",
    "\n",
    "\n",
    "    class CalendarEvent(BaseModel):\n",
    "        name: str\n",
    "        date: str\n",
    "        participants: list[str]\n",
    "\n",
    "    agent = Agent(\n",
    "        name=\"Calendar extractor\",\n",
    "        instructions=\"Extract calendar events from text\",\n",
    "        output_type=CalendarEvent,\n",
    "    )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4057f49f",
   "metadata": {},
   "source": [
    "## **`Note`**\n",
    "\n",
    "When you pass an `output_type`, that tells the model to use structured outputs instead of regular plain text responses.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce8455d",
   "metadata": {},
   "source": [
    "### **Handoffs**:\n",
    "\n",
    "  * Sub-agents that the main agent can delegate tasks to.\n",
    "  * You provide a list of handoffs, and the agent can delegate to the relevant sub-agent based on the situation.\n",
    "  * This enables modular, specialized agents that focus on specific tasks, improving efficiency and flexibility.\n",
    "\n",
    "* **Example Setup**:\n",
    "\n",
    "  * Create agents that specialize in specific tasks:\n",
    "\n",
    "    ```python\n",
    "    from agents import Agent\n",
    "\n",
    "    booking_agent = Agent(...)\n",
    "    refund_agent = Agent(...)\n",
    "    ```\n",
    "\n",
    "* **Triage Agent with Handoffs**:\n",
    "\n",
    "  * The triage agent manages queries and delegates to the appropriate agent (e.g., booking or refund) based on the userâ€™s inquiry.\n",
    "\n",
    "    ```python\n",
    "    triage_agent = Agent(\n",
    "        name=\"Triage agent\",\n",
    "        instructions=(\n",
    "            \"Help the user with their questions. \"\n",
    "            \"If they ask about booking, handoff to the booking agent. \"\n",
    "            \"If they ask about refunds, handoff to the refund agent.\"\n",
    "        ),\n",
    "        handoffs=[booking_agent, refund_agent],\n",
    "    )\n",
    "    ```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f931c8",
   "metadata": {},
   "source": [
    "### *Dynamic instructions*\n",
    "\n",
    "We can provide instructions when you create the agent.\n",
    "\n",
    "However, you can also provide dynamic instructions via a function. The function will receive the agent and context, and must return the prompt. \n",
    "\n",
    "Both regular and async functions are accepted.\n",
    "\n",
    "```python\n",
    "def dynamic_instructions(\n",
    "    context: RunContextWrapper[UserContext], agent: Agent[UserContext]\n",
    ") -> str:\n",
    "    return f\"The user's name is {context.context.name}. Help them with their questions.\"\n",
    "\n",
    "\n",
    "agent = Agent[UserContext](\n",
    "    name=\"Triage agent\",\n",
    "    instructions=dynamic_instructions,\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a7da1e",
   "metadata": {},
   "source": [
    "### **Lifecycle events (hooks)**\n",
    "Sometimes, you want to observe the lifecycle of an agent. For example, you may want to log events, or pre-fetch data when certain events occur. You can hook into the agent lifecycle with the hooks property. Subclass the `AgentHooks` class, and override the methods you're interested in."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529496d2",
   "metadata": {},
   "source": [
    "### **Guardrails**\n",
    "Guardrails allow you to run checks/validations on user input, in parallel to the agent running. For example, you could screen the user's input for relevance. Read more in the `guardrails` documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d63796a",
   "metadata": {},
   "source": [
    "## **Cloning/copying agents**\n",
    "By using the `clone()` method on an agent, you can `duplicate` an `Agent`, and optionally change any properties you like.\n",
    "\n",
    "```python\n",
    "pirate_agent = Agent(\n",
    "    name=\"Pirate\",\n",
    "    instructions=\"Write like a pirate\",\n",
    "    model=\"o3-mini\",\n",
    ")\n",
    "\n",
    "robot_agent = pirate_agent.clone(\n",
    "    name=\"Robot\",\n",
    "    instructions=\"Write like a robot\",\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f61ead8",
   "metadata": {},
   "source": [
    "### **Forcing tool use**\n",
    "Supplying a list of tools doesn't always mean the LLM will use a tool. You can force tool use by setting ModelSettings.tool_choice. Valid values are:\n",
    "\n",
    "- auto, which allows the LLM to decide whether or not to use a tool.\n",
    "- required, which requires the LLM to use a tool (but it can intelligently decide which tool).\n",
    "- none, which requires the LLM to not use a tool.\n",
    "- Setting a specific string e.g. my_tool, which requires the LLM to use that specific tool."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244d6ec5",
   "metadata": {},
   "source": [
    "## **`Note`**\n",
    "\n",
    "To prevent infinite loops, the framework automatically resets `tool_choice` to \"auto\" after a tool call. This behavior is configurable via agent.reset_`tool_choice`. The infinite loop is because tool results are sent to the LLM, which then generates another tool call because of `tool_choice`, ad infinitum.\n",
    "\n",
    "If you want the Agent to completely stop after a tool call (rather than continuing with auto mode), you can set `[Agent.tool_use_behavior=\"stop_on_first_tool\"]` which will directly use the tool output as the final response without further LLM processing."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentic_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
